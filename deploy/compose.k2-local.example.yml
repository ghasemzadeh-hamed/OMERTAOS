services:
  # \u0627\u06cc\u0646 \u0633\u0631\u0648\u06cc\u0633 \u0628\u0627\u06cc\u062f \u06cc\u06a9 \u0633\u0631\u0648\u0631 OpenAI-compatible \u0631\u0648\u06cc /v1 \u0627\u0631\u0627\u0626\u0647 \u06a9\u0646\u062f.
  # \u0645\u06cc\u200c\u062a\u0648\u0627\u0646\u06cc sglang \u06cc\u0627 vLLM \u0631\u0627 \u062c\u0627\u06cc\u06af\u0632\u06cc\u0646 \u06a9\u0646\u06cc\u060c \u0637\u0628\u0642 \u062f\u0627\u06a9\u06cc\u0648\u0645\u0646\u062a \u0631\u0633\u0645\u06cc \u0647\u0645\u0627\u0646 \u0627\u0646\u062c\u06cc\u0646.
  k2-local:
    image: <your-sglang-or-vllm-image>
    container_name: k2-local
    restart: unless-stopped
    ports:
      - "8000:8000"
    shm_size: "16g"
    environment:
      HF_TOKEN: ${HF_TOKEN}
      # \u0645\u0633\u06cc\u0631 \u0645\u062f\u0644 \u0631\u0627 \u0631\u0648\u06cc \u0648\u0644\u0648\u0645 \u0628\u062f\u0647\u061b \u0628\u0631\u0627\u06cc INT4 (Thinking) \u0627\u0632 \u0686\u06a9\u200c\u067e\u0648\u06cc\u0646\u062a INT4 \u0627\u0633\u062a\u0641\u0627\u062f\u0647 \u06a9\u0646.
    volumes:
      - /data/models/kimi-k2:/models/kimi-k2
    command: >
      bash -lc "
      python3 -m <engine>.launch_server
        --model-path /models/kimi-k2
        --port 8000
        --tensor-parallel-size 8
        --enable-moe
        --max-model-len 131072
      "

# \u0628\u0631\u0627\u06cc \u0631\u0627\u0647\u200c\u0627\u0646\u062f\u0627\u0632\u06cc \u062a\u0648\u0632\u06cc\u0639\u200c\u0634\u062f\u0647/Disaggregated \u0633\u0631\u0648\u06cc\u0646\u06af \u0648 MoE-EP\u060c \u0631\u0627\u0647\u0646\u0645\u0627\u0647\u0627\u06cc SGLang Router / PD-disaggregation \u0631\u0627 \u0628\u0628\u06cc\u0646.
